{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Ultralytics Models: A Comprehensive Course\n",
    "\n",
    "## Course Overview\n",
    "\n",
    "Welcome to this comprehensive guide on fine-tuning state-of-the-art object detection models from Ultralytics. In this course, you will learn how to:\n",
    "\n",
    "- Fine-tune **YOLOv5, YOLOv8, YOLOv9, YOLOv10, YOLOv11**, and **RT-DETR**\n",
    "- Train models on custom datasets\n",
    "- Run inference and evaluate model performance\n",
    "- Modify and optimize hyperparameters\n",
    "- Apply advanced training techniques\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Fine-Tuning](#1-introduction)\n",
    "2. [Prerequisites and Setup](#2-setup)\n",
    "3. [Dataset Preparation](#3-dataset)\n",
    "4. [YOLOv5 Fine-Tuning](#4-yolov5)\n",
    "5. [YOLOv8 Fine-Tuning](#5-yolov8)\n",
    "6. [YOLOv9 Fine-Tuning](#6-yolov9)\n",
    "7. [YOLOv10 Fine-Tuning](#7-yolov10)\n",
    "8. [YOLOv11 Fine-Tuning](#8-yolov11)\n",
    "9. [RT-DETR Fine-Tuning](#9-rtdetr)\n",
    "10. [Hyperparameter Tuning Guide](#10-hyperparameters)\n",
    "11. [Advanced Techniques](#11-advanced)\n",
    "12. [Comparison and Best Practices](#12-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to Fine-Tuning <a id=\"1-introduction\"></a>\n",
    "\n",
    "### What is Fine-Tuning?\n",
    "\n",
    "Fine-tuning is the process of taking a pre-trained model and adapting it to a specific task or dataset. Instead of training a model from scratch, we leverage the knowledge the model has already learned from large datasets.\n",
    "\n",
    "### Why Fine-Tune?\n",
    "\n",
    "- **Faster Training**: Pre-trained models already understand basic features\n",
    "- **Better Performance**: Especially with limited data\n",
    "- **Less Data Required**: Can achieve good results with smaller datasets\n",
    "- **Resource Efficient**: Requires less computational power than training from scratch\n",
    "\n",
    "### Model Overview\n",
    "\n",
    "| Model | Release | Key Features | Speed | Accuracy |\n",
    "|-------|---------|--------------|-------|----------|\n",
    "| YOLOv5 | 2020 | Mature, stable, excellent documentation | Fast | Good |\n",
    "| YOLOv8 | 2023 | Unified API, multiple tasks support | Very Fast | Better |\n",
    "| YOLOv9 | 2024 | Programmable gradient information | Fast | Excellent |\n",
    "| YOLOv10 | 2024 | Real-time end-to-end detection | Very Fast | Excellent |\n",
    "| YOLOv11 | 2024 | Latest, state-of-the-art performance | Very Fast | Best |\n",
    "| RT-DETR | 2023 | Transformer-based, no NMS needed | Fast | Excellent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prerequisites and Setup <a id=\"2-setup\"></a>\n",
    "\n",
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics package (includes YOLOv8, YOLOv9, YOLOv10, YOLOv11, RT-DETR)\n",
    "!pip install -q ultralytics\n",
    "\n",
    "# Install YOLOv5 (separate repository)\n",
    "!pip install -q yolov5\n",
    "\n",
    "# Additional useful libraries\n",
    "!pip install -q roboflow  # For dataset management\n",
    "!pip install -q pillow numpy matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Check for GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ultralytics version\n",
    "import ultralytics\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "# Verify installation\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset Preparation <a id=\"3-dataset\"></a>\n",
    "\n",
    "### Dataset Format\n",
    "\n",
    "All Ultralytics models use the YOLO format for datasets:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   └── val/\n",
    "│       ├── image1.jpg\n",
    "│       └── ...\n",
    "└── labels/\n",
    "    ├── train/\n",
    "    │   ├── image1.txt\n",
    "    │   ├── image2.txt\n",
    "    │   └── ...\n",
    "    └── val/\n",
    "        ├── image1.txt\n",
    "        └── ...\n",
    "```\n",
    "\n",
    "### Label Format\n",
    "\n",
    "Each `.txt` file contains one line per object:\n",
    "```\n",
    "class_id center_x center_y width height\n",
    "```\n",
    "\n",
    "Where all coordinates are normalized (0-1):\n",
    "- `class_id`: Integer starting from 0\n",
    "- `center_x`, `center_y`: Center coordinates of bounding box\n",
    "- `width`, `height`: Width and height of bounding box\n",
    "\n",
    "Example:\n",
    "```\n",
    "0 0.5 0.5 0.3 0.4\n",
    "1 0.2 0.3 0.15 0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset Configuration File\n",
    "\n",
    "Create a YAML file describing your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a dataset.yaml file\n",
    "dataset_yaml = \"\"\"\n",
    "# Dataset configuration\n",
    "path: /path/to/dataset  # Root directory\n",
    "train: images/train  # Training images (relative to 'path')\n",
    "val: images/val  # Validation images (relative to 'path')\n",
    "\n",
    "# Number of classes\n",
    "nc: 2\n",
    "\n",
    "# Class names\n",
    "names: ['class1', 'class2']\n",
    "\"\"\"\n",
    "\n",
    "# Save the configuration\n",
    "with open('dataset.yaml', 'w') as f:\n",
    "    f.write(dataset_yaml)\n",
    "\n",
    "print(\"Dataset configuration saved to 'dataset.yaml'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Sample Dataset (COCO8 for demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://universe.roboflow.com/timilehin-morighanfen-v8icx/vehicles-5rakd/dataset/1/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. YOLOv5 Fine-Tuning <a id=\"4-yolov5\"></a>\n",
    "\n",
    "YOLOv5 is a mature and widely-used object detection model with excellent documentation and community support.\n",
    "\n",
    "### 4.1 Training YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone YOLOv5 repository (if not already done)\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5\n",
    "    !pip install -q -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training YOLOv5 using the command line approach\n",
    "!python yolov5/train.py \\\n",
    "    --img 640 \\\n",
    "    --batch 16 \\\n",
    "    --epochs 50 \\\n",
    "    --data {dataset_path} \\\n",
    "    --weights yolov5s.pt \\\n",
    "    --device 0 \\\n",
    "    --project runs/yolov5 \\\n",
    "    --name custom_training \\\n",
    "    --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 YOLOv5 Training with Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Using Python API\n",
    "import torch\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Training is still typically done via the train.py script\n",
    "# But you can use the yolov5 package for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 YOLOv5 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model for inference\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                       path='runs/yolov5/custom_training/weights/best.pt')\n",
    "\n",
    "# Run inference on an image\n",
    "img_path = 'path/to/test/image.jpg'\n",
    "results = model(img_path)\n",
    "\n",
    "# Display results\n",
    "results.show()\n",
    "\n",
    "# Print detections\n",
    "results.print()\n",
    "\n",
    "# Get pandas dataframe with results\n",
    "df = results.pandas().xyxy[0]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 YOLOv5 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 training with custom hyperparameters\n",
    "!python yolov5/train.py \\\n",
    "    --img 640 \\\n",
    "    --batch 16 \\\n",
    "    --epochs 100 \\\n",
    "    --data {dataset_path} \\\n",
    "    --weights yolov5s.pt \\\n",
    "    --device 0 \\\n",
    "    --project runs/yolov5 \\\n",
    "    --name custom_hyperparams \\\n",
    "    --hyp data/hyps/hyp.scratch-low.yaml \\\n",
    "    --optimizer Adam \\\n",
    "    --lr0 0.001 \\\n",
    "    --lrf 0.01 \\\n",
    "    --momentum 0.937 \\\n",
    "    --weight-decay 0.0005 \\\n",
    "    --warmup-epochs 3.0 \\\n",
    "    --cos-lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 YOLOv5 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the trained model\n",
    "!python yolov5/val.py \\\n",
    "    --weights runs/yolov5/custom_training/weights/best.pt \\\n",
    "    --data {dataset_path} \\\n",
    "    --img 640 \\\n",
    "    --batch 16 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. YOLOv8 Fine-Tuning <a id=\"5-yolov8\"></a>\n",
    "\n",
    "YOLOv8 introduced a unified API that makes training and inference much simpler. It supports multiple tasks: detection, segmentation, classification, and pose estimation.\n",
    "\n",
    "### 5.1 Training YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "# Available models: yolov8n, yolov8s, yolov8m, yolov8l, yolov8x\n",
    "# n=nano (smallest), s=small, m=medium, l=large, x=xlarge (biggest)\n",
    "model = YOLO('yolov8n.pt')  # Load the nano model\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,  # GPU device, or 'cpu'\n",
    "    project='runs/yolov8',\n",
    "    name='custom_training',\n",
    "    patience=50,\n",
    "    save=True,\n",
    "    cache=True,\n",
    "    pretrained=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 YOLOv8 Training with Custom Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Training with detailed hyperparameters\n",
    "results = model.train(\n",
    "    # Dataset\n",
    "    data=dataset_path,\n",
    "    \n",
    "    # Training duration\n",
    "    epochs=100,\n",
    "    time=None,  # Maximum training time in hours\n",
    "    patience=50,\n",
    "    \n",
    "    # Batch and image size\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    \n",
    "    # Learning rate settings\n",
    "    lr0=0.01,  # Initial learning rate\n",
    "    lrf=0.01,  # Final learning rate (lr0 * lrf)\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='SGD',  # Options: 'SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp'\n",
    "    \n",
    "    # Loss weights\n",
    "    box=7.5,  # Box loss weight\n",
    "    cls=0.5,  # Classification loss weight\n",
    "    dfl=1.5,  # Distribution focal loss weight\n",
    "    \n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,  # Hue augmentation\n",
    "    hsv_s=0.7,    # Saturation augmentation\n",
    "    hsv_v=0.4,    # Value augmentation\n",
    "    degrees=0.0,   # Rotation\n",
    "    translate=0.1, # Translation\n",
    "    scale=0.5,     # Scale\n",
    "    shear=0.0,     # Shear\n",
    "    perspective=0.0,  # Perspective\n",
    "    flipud=0.0,    # Flip up-down\n",
    "    fliplr=0.5,    # Flip left-right\n",
    "    mosaic=1.0,    # Mosaic augmentation\n",
    "    mixup=0.0,     # Mixup augmentation\n",
    "    copy_paste=0.0,  # Copy-paste augmentation\n",
    "    \n",
    "    # Advanced settings\n",
    "    cos_lr=False,  # Use cosine learning rate scheduler\n",
    "    close_mosaic=10,  # Disable mosaic in last N epochs\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    "    fraction=1.0,  # Dataset fraction to use\n",
    "    \n",
    "    # Device and workers\n",
    "    device=0,\n",
    "    workers=8,\n",
    "    \n",
    "    # Project settings\n",
    "    project='runs/yolov8',\n",
    "    name='hyperparameter_tuning',\n",
    "    exist_ok=False,\n",
    "    \n",
    "    # Saving and validation\n",
    "    save=True,\n",
    "    save_period=-1,  # Save checkpoint every N epochs (-1 to disable)\n",
    "    val=True,\n",
    "    plots=True,\n",
    "    \n",
    "    # Other\n",
    "    cache=True,\n",
    "    rect=False,  # Rectangular training\n",
    "    resume=False,  # Resume training\n",
    "    seed=0,\n",
    "    deterministic=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 YOLOv8 Automatic Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Tune hyperparameters using genetic algorithms\n",
    "# This will automatically search for the best hyperparameters\n",
    "results = model.tune(\n",
    "    data=dataset_path,\n",
    "    epochs=30,  # Epochs per tuning iteration\n",
    "    iterations=300,  # Number of tuning iterations\n",
    "    optimizer='AdamW',\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    val=True\n",
    ")\n",
    "\n",
    "print(\"Hyperparameter tuning completed!\")\n",
    "print(f\"Best hyperparameters: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 YOLOv8 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO('runs/yolov8/custom_training/weights/best.pt')\n",
    "\n",
    "# Single image inference\n",
    "results = model('path/to/image.jpg')\n",
    "\n",
    "# Display results\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    \n",
    "# Get predictions\n",
    "boxes = results[0].boxes  # Boxes object\n",
    "print(f\"Detected {len(boxes)} objects\")\n",
    "print(f\"Class IDs: {boxes.cls}\")\n",
    "print(f\"Confidences: {boxes.conf}\")\n",
    "print(f\"Bounding boxes: {boxes.xyxy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with custom parameters\n",
    "results = model.predict(\n",
    "    source='path/to/image.jpg',\n",
    "    conf=0.25,  # Confidence threshold\n",
    "    iou=0.45,   # NMS IoU threshold\n",
    "    imgsz=640,  # Image size\n",
    "    device=0,   # GPU device\n",
    "    save=True,  # Save results\n",
    "    save_txt=True,  # Save results as .txt\n",
    "    save_conf=True,  # Save confidences in .txt\n",
    "    classes=[0, 1],  # Filter by class (optional)\n",
    "    agnostic_nms=False,  # Class-agnostic NMS\n",
    "    max_det=300,  # Maximum detections per image\n",
    "    project='runs/detect',\n",
    "    name='exp',\n",
    "    show=True,  # Show results\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Batch inference (multiple images, video, directory)\n",
    "results = model.predict(\n",
    "    source='path/to/images/',  # Can be directory, video, URL, etc.\n",
    "    stream=True  # Use streaming for memory efficiency with large datasets\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Processing: {result.path}\")\n",
    "    boxes = result.boxes\n",
    "    print(f\"Found {len(boxes)} objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 YOLOv8 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('runs/yolov8/custom_training/weights/best.pt')\n",
    "\n",
    "# Validate model\n",
    "metrics = model.val(\n",
    "    data=dataset_path,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    conf=0.25,\n",
    "    iou=0.6,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(f\"mAP50: {metrics.box.map50}\")\n",
    "print(f\"mAP50-95: {metrics.box.map}\")\n",
    "print(f\"Precision: {metrics.box.mp}\")\n",
    "print(f\"Recall: {metrics.box.mr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 YOLOv8 Export (for deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('runs/yolov8/custom_training/weights/best.pt')\n",
    "\n",
    "# Export to different formats\n",
    "model.export(format='onnx')  # ONNX\n",
    "model.export(format='torchscript')  # TorchScript\n",
    "model.export(format='coreml')  # CoreML\n",
    "model.export(format='tflite')  # TensorFlow Lite\n",
    "model.export(format='engine')  # TensorRT\n",
    "\n",
    "print(\"Model exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. YOLOv9 Fine-Tuning <a id=\"6-yolov9\"></a>\n",
    "\n",
    "YOLOv9 introduced Programmable Gradient Information (PGI) and Generalized Efficient Layer Aggregation Network (GELAN), improving accuracy without increasing computational cost.\n",
    "\n",
    "### 6.1 Training YOLOv9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv9 model\n",
    "# Available models: yolov9t, yolov9s, yolov9m, yolov9c, yolov9e\n",
    "model = YOLO('yolov9c.pt')  # Load YOLOv9c\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    project='runs/yolov9',\n",
    "    name='custom_training',\n",
    "    optimizer='SGD',\n",
    "    lr0=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    cos_lr=True,\n",
    "    patience=50,\n",
    "    cache=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"YOLOv9 training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 YOLOv9 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv9 supports the same tuning API as YOLOv8\n",
    "model = YOLO('yolov9c.pt')\n",
    "\n",
    "# Automatic hyperparameter tuning\n",
    "results = model.tune(\n",
    "    data=dataset_path,\n",
    "    epochs=30,\n",
    "    iterations=300,\n",
    "    optimizer='AdamW',\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    val=True\n",
    ")\n",
    "\n",
    "print(f\"Best hyperparameters: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 YOLOv9 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained YOLOv9 model\n",
    "model = YOLO('runs/yolov9/custom_training/weights/best.pt')\n",
    "\n",
    "# Run inference (same API as YOLOv8)\n",
    "results = model.predict(\n",
    "    source='path/to/image.jpg',\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    save=True,\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Process results\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    print(f\"Detected {len(boxes)} objects\")\n",
    "    print(f\"Classes: {boxes.cls}\")\n",
    "    print(f\"Confidences: {boxes.conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. YOLOv10 Fine-Tuning <a id=\"7-yolov10\"></a>\n",
    "\n",
    "YOLOv10 introduced NMS-free training and efficient architecture design, achieving real-time performance with state-of-the-art accuracy.\n",
    "\n",
    "### 7.1 Training YOLOv10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv10 model\n",
    "# Available models: yolov10n, yolov10s, yolov10m, yolov10b, yolov10l, yolov10x\n",
    "model = YOLO('yolov10n.pt')  # Load YOLOv10-nano\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    project='runs/yolov10',\n",
    "    name='custom_training',\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    cos_lr=True,\n",
    "    close_mosaic=10,\n",
    "    amp=True,\n",
    "    patience=50,\n",
    "    cache=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"YOLOv10 training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 YOLOv10 with Advanced Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov10s.pt')\n",
    "\n",
    "# Training with multi-scale and advanced augmentation\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=150,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    \n",
    "    # Multi-scale training\n",
    "    multi_scale=True,\n",
    "    \n",
    "    # Advanced augmentation\n",
    "    mosaic=1.0,\n",
    "    mixup=0.15,\n",
    "    copy_paste=0.1,\n",
    "    degrees=10.0,\n",
    "    translate=0.2,\n",
    "    scale=0.9,\n",
    "    fliplr=0.5,\n",
    "    flipud=0.1,\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,\n",
    "    cos_lr=True,\n",
    "    \n",
    "    # Other settings\n",
    "    device=0,\n",
    "    project='runs/yolov10',\n",
    "    name='advanced_training',\n",
    "    patience=75,\n",
    "    val=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 YOLOv10 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained YOLOv10 model\n",
    "model = YOLO('runs/yolov10/custom_training/weights/best.pt')\n",
    "\n",
    "# YOLOv10 doesn't require NMS, making inference faster\n",
    "results = model.predict(\n",
    "    source='path/to/image.jpg',\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    show=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Process results\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    print(f\"Detected {len(boxes)} objects\")\n",
    "    for i, box in enumerate(boxes):\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        print(f\"Object {i+1}: Class={cls}, Confidence={conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. YOLOv11 Fine-Tuning <a id=\"8-yolov11\"></a>\n",
    "\n",
    "YOLOv11 is the latest and most advanced YOLO version, offering state-of-the-art performance across all tasks with improved architecture and training techniques.\n",
    "\n",
    "### 8.1 Training YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv11 model\n",
    "# Available models: yolo11n, yolo11s, yolo11m, yolo11l, yolo11x\n",
    "model = YOLO('yolo11n.pt')  # or 'yolo11s.pt', 'yolo11m.pt', etc.\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    project='runs/yolo11',\n",
    "    name='custom_training',\n",
    "    optimizer='auto',  # Auto-select best optimizer\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    cos_lr=True,\n",
    "    patience=50,\n",
    "    cache=True,\n",
    "    amp=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"YOLOv11 training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 YOLOv11 with PyTorch 2.x Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "# Use PyTorch 2.x torch.compile for faster training (requires PyTorch >= 2.0)\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    \n",
    "    # Enable compilation for speed boost\n",
    "    compile=True,  # or 'default', 'reduce-overhead', 'max-autotune'\n",
    "    \n",
    "    # Other settings\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    cos_lr=True,\n",
    "    amp=True,\n",
    "    project='runs/yolo11',\n",
    "    name='compiled_training',\n",
    "    patience=50\n",
    ")\n",
    "\n",
    "print(\"Compiled training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 YOLOv11 Transfer Learning with Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11m.pt')\n",
    "\n",
    "# Freeze the first 10 layers (backbone)\n",
    "# This speeds up training and can improve performance on small datasets\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    \n",
    "    # Freeze backbone layers\n",
    "    freeze=10,  # Freeze first 10 layers, or use [0,1,2,3] for specific layers\n",
    "    \n",
    "    # Use higher learning rate since we're only training head\n",
    "    lr0=0.01,\n",
    "    \n",
    "    project='runs/yolo11',\n",
    "    name='transfer_learning',\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "print(\"Transfer learning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 YOLOv11 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Load trained YOLOv11 model\n",
    "model = YOLO('runs/yolo11/custom_training/weights/best.pt')\n",
    "\n",
    "# Single image inference\n",
    "results = model.predict(\n",
    "    source='path/to/image.jpg',\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    save=True,\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Video inference\n",
    "results = model.predict(\n",
    "    source='path/to/video.mp4',\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    stream=True  # Stream for memory efficiency\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    print(f\"Frame: {r.path}, Objects: {len(boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 YOLOv11 Real-time Webcam Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = YOLO('runs/yolo11/custom_training/weights/best.pt')\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(frame, conf=0.25, verbose=False)\n",
    "    \n",
    "    # Visualize results\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('YOLOv11 Inference', annotated_frame)\n",
    "    \n",
    "    # Break on 'q' press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. RT-DETR Fine-Tuning <a id=\"9-rtdetr\"></a>\n",
    "\n",
    "RT-DETR (Real-Time DEtection TRansformer) is a transformer-based detector that doesn't require Non-Maximum Suppression (NMS), making it more efficient for deployment.\n",
    "\n",
    "### 9.1 Training RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "# Load a pre-trained RT-DETR model\n",
    "# Available models: rtdetr-l, rtdetr-x\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,  # RT-DETR uses more memory, may need smaller batch\n",
    "    device=0,\n",
    "    project='runs/rtdetr',\n",
    "    name='custom_training',\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.0001,  # Lower learning rate for transformers\n",
    "    lrf=0.0001,\n",
    "    weight_decay=0.0001,\n",
    "    warmup_epochs=5.0,  # Longer warmup for transformers\n",
    "    patience=50,\n",
    "    cache=False,  # May need to disable cache due to memory\n",
    "    amp=False,  # RT-DETR can have issues with AMP\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"RT-DETR training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 RT-DETR with Custom Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "# RT-DETR specific training configuration\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    \n",
    "    # Optimizer settings (important for transformers)\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.0001,\n",
    "    lrf=0.00001,\n",
    "    weight_decay=0.0001,\n",
    "    \n",
    "    # Warmup (critical for transformer training)\n",
    "    warmup_epochs=5.0,\n",
    "    warmup_momentum=0.5,\n",
    "    warmup_bias_lr=0.0001,\n",
    "    \n",
    "    # Loss weights (may need adjustment for RT-DETR)\n",
    "    box=5.0,\n",
    "    cls=0.5,\n",
    "    \n",
    "    # Data augmentation (transformers benefit from strong augmentation)\n",
    "    mosaic=1.0,\n",
    "    mixup=0.1,\n",
    "    copy_paste=0.1,\n",
    "    degrees=10.0,\n",
    "    translate=0.2,\n",
    "    scale=0.9,\n",
    "    \n",
    "    # Other settings\n",
    "    device=0,\n",
    "    project='runs/rtdetr',\n",
    "    name='optimized_training',\n",
    "    patience=50,\n",
    "    amp=False,  # Disable AMP for stability\n",
    "    deterministic=False,  # RT-DETR doesn't support deterministic\n",
    "    val=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 RT-DETR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "# Load trained RT-DETR model\n",
    "model = RTDETR('runs/rtdetr/custom_training/weights/best.pt')\n",
    "\n",
    "# RT-DETR doesn't use NMS, so no iou parameter\n",
    "results = model.predict(\n",
    "    source='path/to/image.jpg',\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    show=True\n",
    ")\n",
    "\n",
    "# Process results\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    print(f\"Detected {len(boxes)} objects (NMS-free)\")\n",
    "    print(f\"Classes: {boxes.cls}\")\n",
    "    print(f\"Confidences: {boxes.conf}\")\n",
    "    print(f\"Boxes: {boxes.xyxy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 RT-DETR vs YOLO Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import RTDETR, YOLO\n",
    "import time\n",
    "\n",
    "# Load models\n",
    "rtdetr = RTDETR('rtdetr-l.pt')\n",
    "yolo11 = YOLO('yolo11m.pt')\n",
    "\n",
    "# Test image\n",
    "test_image = 'path/to/test/image.jpg'\n",
    "\n",
    "# RT-DETR inference\n",
    "start = time.time()\n",
    "rtdetr_results = rtdetr.predict(test_image, verbose=False)\n",
    "rtdetr_time = time.time() - start\n",
    "\n",
    "# YOLO inference\n",
    "start = time.time()\n",
    "yolo_results = yolo11.predict(test_image, verbose=False)\n",
    "yolo_time = time.time() - start\n",
    "\n",
    "print(f\"RT-DETR: {len(rtdetr_results[0].boxes)} objects, {rtdetr_time*1000:.2f}ms\")\n",
    "print(f\"YOLOv11: {len(yolo_results[0].boxes)} objects, {yolo_time*1000:.2f}ms\")\n",
    "print(f\"\\nRT-DETR advantage: No NMS required, more accurate for crowded scenes\")\n",
    "print(f\"YOLO advantage: Faster inference, lower memory usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Comprehensive Hyperparameter Tuning Guide <a id=\"10-hyperparameters\"></a>\n",
    "\n",
    "### 10.1 Understanding Key Hyperparameters\n",
    "\n",
    "#### Training Duration\n",
    "- **epochs**: Number of complete passes through the dataset\n",
    "- **patience**: Early stopping if no improvement for N epochs\n",
    "- **time**: Maximum training time in hours\n",
    "\n",
    "#### Batch and Image Size\n",
    "- **batch**: Number of images per batch\n",
    "  - Larger batch = more stable gradients but more memory\n",
    "  - Use `-1` for auto batch size (60% GPU memory)\n",
    "  - Use `0.7` for 70% GPU memory\n",
    "- **imgsz**: Input image size (e.g., 640, 1280)\n",
    "  - Larger size = better accuracy but slower training\n",
    "\n",
    "#### Learning Rate\n",
    "- **lr0**: Initial learning rate\n",
    "  - SGD: typically 0.01\n",
    "  - Adam/AdamW: typically 0.001\n",
    "- **lrf**: Final learning rate (lr0 * lrf)\n",
    "- **momentum**: Momentum factor (SGD only)\n",
    "- **weight_decay**: L2 regularization\n",
    "\n",
    "#### Warmup\n",
    "- **warmup_epochs**: Gradually increase LR for stability\n",
    "- **warmup_momentum**: Initial momentum during warmup\n",
    "- **warmup_bias_lr**: Learning rate for bias parameters\n",
    "\n",
    "#### Loss Weights\n",
    "- **box**: Bounding box loss weight\n",
    "- **cls**: Classification loss weight\n",
    "- **dfl**: Distribution focal loss weight\n",
    "\n",
    "#### Data Augmentation\n",
    "- **mosaic**: Combine 4 images (0-1)\n",
    "- **mixup**: Blend 2 images (0-1)\n",
    "- **copy_paste**: Copy objects between images (0-1)\n",
    "- **degrees**: Random rotation (-180 to +180)\n",
    "- **translate**: Random translation (0-1)\n",
    "- **scale**: Random scaling (>=0)\n",
    "- **shear**: Random shearing (-180 to +180)\n",
    "- **fliplr**: Horizontal flip probability (0-1)\n",
    "- **flipud**: Vertical flip probability (0-1)\n",
    "- **hsv_h/s/v**: Color jittering (0-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Hyperparameter Recipes for Different Scenarios\n",
    "\n",
    "#### Small Dataset (< 1000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Small dataset configuration\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=200,  # More epochs for small datasets\n",
    "    patience=100,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    \n",
    "    # Use pretrained weights and freeze backbone\n",
    "    pretrained=True,\n",
    "    freeze=10,  # Freeze backbone layers\n",
    "    \n",
    "    # Higher learning rate since we're only training head\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    \n",
    "    # Strong augmentation to prevent overfitting\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.2,\n",
    "    degrees=15.0,\n",
    "    translate=0.2,\n",
    "    scale=0.9,\n",
    "    shear=5.0,\n",
    "    fliplr=0.5,\n",
    "    flipud=0.1,\n",
    "    \n",
    "    # Regularization\n",
    "    weight_decay=0.001,  # Higher weight decay\n",
    "    dropout=0.0,\n",
    "    \n",
    "    project='runs/small_dataset',\n",
    "    name='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Dataset (> 10,000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11m.pt')\n",
    "\n",
    "# Large dataset configuration\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,  # Fewer epochs sufficient\n",
    "    patience=50,\n",
    "    batch=-1,  # Auto batch size\n",
    "    imgsz=640,\n",
    "    \n",
    "    # Can train from scratch or with less freezing\n",
    "    pretrained=True,\n",
    "    freeze=0,  # No freezing\n",
    "    \n",
    "    # Standard learning rate\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    cos_lr=True,  # Cosine learning rate schedule\n",
    "    \n",
    "    # Moderate augmentation\n",
    "    mosaic=1.0,\n",
    "    mixup=0.1,\n",
    "    copy_paste=0.1,\n",
    "    degrees=10.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    \n",
    "    # Multi-scale training\n",
    "    multi_scale=True,\n",
    "    \n",
    "    # Standard regularization\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Performance optimizations\n",
    "    cache=True,\n",
    "    amp=True,\n",
    "    workers=8,\n",
    "    \n",
    "    project='runs/large_dataset',\n",
    "    name='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Accuracy (Competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11x.pt')  # Use largest model\n",
    "\n",
    "# Competition/high-accuracy configuration\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=300,  # Long training\n",
    "    patience=100,\n",
    "    batch=8,  # Smaller batch for large model\n",
    "    imgsz=1280,  # Large image size\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.0001,\n",
    "    cos_lr=True,\n",
    "    \n",
    "    # Strong augmentation\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.3,\n",
    "    degrees=15.0,\n",
    "    translate=0.2,\n",
    "    scale=0.9,\n",
    "    shear=5.0,\n",
    "    perspective=0.0005,\n",
    "    fliplr=0.5,\n",
    "    flipud=0.1,\n",
    "    \n",
    "    # Multi-scale\n",
    "    multi_scale=True,\n",
    "    \n",
    "    # Close mosaic late\n",
    "    close_mosaic=50,\n",
    "    \n",
    "    # Best quality\n",
    "    rect=False,\n",
    "    amp=True,\n",
    "    \n",
    "    project='runs/high_accuracy',\n",
    "    name='training',\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast Training (Quick Experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')  # Use smallest model\n",
    "\n",
    "# Fast training configuration\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=50,  # Few epochs\n",
    "    patience=20,\n",
    "    batch=-1,  # Auto batch size\n",
    "    imgsz=640,  # Standard size\n",
    "    \n",
    "    # Fast optimizer\n",
    "    optimizer='SGD',\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    \n",
    "    # Light augmentation\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    "    fliplr=0.5,\n",
    "    \n",
    "    # Speed optimizations\n",
    "    cache='ram',  # Cache in RAM\n",
    "    amp=True,\n",
    "    workers=8,\n",
    "    rect=True,  # Rectangular training\n",
    "    \n",
    "    # Less frequent validation\n",
    "    val=True,\n",
    "    \n",
    "    project='runs/fast_training',\n",
    "    name='experiment'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Automatic Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "# Use the tune() method for automatic optimization\n",
    "results = model.tune(\n",
    "    data=dataset_path,\n",
    "    epochs=30,  # Epochs per iteration\n",
    "    iterations=300,  # Number of optimization iterations\n",
    "    optimizer='AdamW',\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    val=True,\n",
    "    cache=True\n",
    ")\n",
    "\n",
    "# The best hyperparameters will be saved automatically\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Manual Hyperparameter Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import itertools\n",
    "\n",
    "# Define hyperparameter grid\n",
    "lr_values = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [8, 16, 32]\n",
    "optimizers = ['SGD', 'Adam', 'AdamW']\n",
    "\n",
    "best_map = 0\n",
    "best_config = {}\n",
    "\n",
    "# Grid search\n",
    "for lr, batch, opt in itertools.product(lr_values, batch_sizes, optimizers):\n",
    "    print(f\"\\nTesting: lr={lr}, batch={batch}, optimizer={opt}\")\n",
    "    \n",
    "    model = YOLO('yolo11n.pt')\n",
    "    \n",
    "    results = model.train(\n",
    "        data=dataset_path,\n",
    "        epochs=30,\n",
    "        lr0=lr,\n",
    "        batch=batch,\n",
    "        optimizer=opt,\n",
    "        project='runs/grid_search',\n",
    "        name=f'lr{lr}_b{batch}_{opt}',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Get validation metrics\n",
    "    metrics = model.val()\n",
    "    map50_95 = metrics.box.map\n",
    "    \n",
    "    print(f\"mAP50-95: {map50_95:.4f}\")\n",
    "    \n",
    "    if map50_95 > best_map:\n",
    "        best_map = map50_95\n",
    "        best_config = {'lr': lr, 'batch': batch, 'optimizer': opt}\n",
    "\n",
    "print(f\"\\nBest configuration: {best_config}\")\n",
    "print(f\"Best mAP50-95: {best_map:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Advanced Techniques <a id=\"11-advanced\"></a>\n",
    "\n",
    "### 11.1 Resume Training from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Resume training from the last checkpoint\n",
    "model = YOLO('runs/yolo11/custom_training/weights/last.pt')\n",
    "\n",
    "# Continue training\n",
    "results = model.train(\n",
    "    resume=True  # Resume from last checkpoint\n",
    ")\n",
    "\n",
    "print(\"Training resumed and completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Multi-GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11m.pt')\n",
    "\n",
    "# Train on multiple GPUs\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    batch=32,  # Total batch size across all GPUs\n",
    "    device=[0, 1],  # Use GPU 0 and GPU 1\n",
    "    # Or use device='0,1,2,3' for 4 GPUs\n",
    "    workers=16,  # More workers for multi-GPU\n",
    "    project='runs/multi_gpu',\n",
    "    name='training'\n",
    ")\n",
    "\n",
    "print(\"Multi-GPU training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Training with Class Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "# Train only on specific classes\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=100,\n",
    "    classes=[0, 2, 5],  # Only train on classes 0, 2, and 5\n",
    "    project='runs/class_subset',\n",
    "    name='training'\n",
    ")\n",
    "\n",
    "print(\"Training on class subset completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Fractional Dataset Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Train on only 20% of the dataset (for quick experiments)\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=50,\n",
    "    fraction=0.2,  # Use only 20% of the data\n",
    "    project='runs/fraction',\n",
    "    name='training'\n",
    ")\n",
    "\n",
    "print(\"Fractional training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Callback Functions for Custom Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def on_train_epoch_end(trainer):\n",
    "    \"\"\"Called at the end of each training epoch.\"\"\"\n",
    "    print(f\"Epoch {trainer.epoch} completed!\")\n",
    "    print(f\"Loss: {trainer.loss}\")\n",
    "\n",
    "def on_val_end(validator):\n",
    "    \"\"\"Called at the end of validation.\"\"\"\n",
    "    print(f\"Validation mAP50: {validator.metrics.box.map50}\")\n",
    "\n",
    "# Create model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Add callbacks\n",
    "model.add_callback('on_train_epoch_end', on_train_epoch_end)\n",
    "model.add_callback('on_val_end', on_val_end)\n",
    "\n",
    "# Train with callbacks\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=50,\n",
    "    project='runs/callbacks',\n",
    "    name='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6 Model Ensemble for Better Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load multiple trained models\n",
    "models = [\n",
    "    YOLO('runs/yolo11/exp1/weights/best.pt'),\n",
    "    YOLO('runs/yolo11/exp2/weights/best.pt'),\n",
    "    YOLO('runs/yolo11/exp3/weights/best.pt')\n",
    "]\n",
    "\n",
    "# Run inference with all models\n",
    "test_image = 'path/to/test/image.jpg'\n",
    "all_results = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    results = model.predict(test_image, verbose=False)\n",
    "    all_results.append(results[0])\n",
    "    print(f\"Model {i+1}: {len(results[0].boxes)} detections\")\n",
    "\n",
    "# You can implement custom NMS or weighted averaging here\n",
    "# For simplicity, we'll use the model with highest confidence\n",
    "best_result = max(all_results, key=lambda x: x.boxes.conf.max() if len(x.boxes) > 0 else 0)\n",
    "\n",
    "print(f\"\\nEnsemble result: {len(best_result.boxes)} objects\")\n",
    "best_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Model Comparison and Best Practices <a id=\"12-comparison\"></a>\n",
    "\n",
    "### 12.1 Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO, RTDETR\n",
    "import time\n",
    "\n",
    "# Models to compare\n",
    "models_to_test = {\n",
    "    'YOLOv5s': 'yolov5s.pt',\n",
    "    'YOLOv8n': 'yolov8n.pt',\n",
    "    'YOLOv9c': 'yolov9c.pt',\n",
    "    'YOLOv10n': 'yolov10n.pt',\n",
    "    'YOLOv11n': 'yolo11n.pt',\n",
    "    'RT-DETR-l': 'rtdetr-l.pt'\n",
    "}\n",
    "\n",
    "results_data = []\n",
    "test_image = 'path/to/test/image.jpg'\n",
    "\n",
    "for name, weight in models_to_test.items():\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    \n",
    "    # Load model\n",
    "    if 'rtdetr' in weight:\n",
    "        model = RTDETR(weight)\n",
    "    else:\n",
    "        model = YOLO(weight)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(3):\n",
    "        _ = model.predict(test_image, verbose=False)\n",
    "    \n",
    "    # Measure inference time\n",
    "    times = []\n",
    "    for _ in range(10):\n",
    "        start = time.time()\n",
    "        results = model.predict(test_image, verbose=False)\n",
    "        times.append((time.time() - start) * 1000)  # Convert to ms\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    num_detections = len(results[0].boxes)\n",
    "    \n",
    "    results_data.append({\n",
    "        'Model': name,\n",
    "        'Inference Time (ms)': avg_time,\n",
    "        'Detections': num_detections\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}: {avg_time:.2f}ms, {num_detections} objects\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "df = pd.DataFrame(results_data)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(df['Model'], df['Inference Time (ms)'])\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Inference Time (ms)')\n",
    "ax.set_title('Model Inference Speed Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Best Practices Summary\n",
    "\n",
    "#### Choosing the Right Model\n",
    "\n",
    "| Use Case | Recommended Model | Why |\n",
    "|----------|------------------|-----|\n",
    "| Real-time on edge devices | YOLOv11n, YOLOv10n | Smallest, fastest |\n",
    "| High accuracy needed | YOLOv11x, RT-DETR-x | Best performance |\n",
    "| Balanced speed/accuracy | YOLOv11s, YOLOv11m | Good tradeoff |\n",
    "| Crowded scenes | RT-DETR | NMS-free, handles overlaps better |\n",
    "| Stable/production | YOLOv5, YOLOv8 | Mature, well-tested |\n",
    "| Latest features | YOLOv11 | Most recent improvements |\n",
    "\n",
    "#### Training Tips\n",
    "\n",
    "1. **Start Small**: Begin with nano/small models for quick experimentation\n",
    "2. **Use Pretrained Weights**: Always start with pretrained models\n",
    "3. **Freeze Layers**: For small datasets, freeze backbone layers\n",
    "4. **Data Augmentation**: Use strong augmentation for small datasets\n",
    "5. **Batch Size**: Use auto batch size (`batch=-1`) if unsure\n",
    "6. **Learning Rate**: Start with defaults, adjust if needed\n",
    "7. **Early Stopping**: Use patience to avoid overfitting\n",
    "8. **Validation**: Always validate during training\n",
    "9. **Cache Data**: Cache images in RAM for faster training\n",
    "10. **AMP**: Enable AMP for faster training (except RT-DETR)\n",
    "\n",
    "#### Common Issues and Solutions\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Out of memory | Reduce batch size or image size |\n",
    "| Low accuracy | Increase epochs, use larger model, more data |\n",
    "| Overfitting | Add augmentation, reduce model size, more data |\n",
    "| Slow training | Enable cache, use smaller model, reduce image size |\n",
    "| Training diverges | Lower learning rate, check data labels |\n",
    "| No improvement | Check dataset quality, try different augmentation |\n",
    "\n",
    "#### Deployment Considerations\n",
    "\n",
    "- **Mobile/Edge**: Use nano models, export to TFLite or CoreML\n",
    "- **Server/Cloud**: Use large models, export to ONNX or TensorRT\n",
    "- **Real-time Video**: Use YOLOv10/YOLOv11 with TensorRT\n",
    "- **High Precision**: Use RT-DETR or YOLOv11x with large image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Complete Training Pipeline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = 'yolo11s.pt'\n",
    "DATA_YAML = 'dataset.yaml'\n",
    "PROJECT_NAME = 'my_project'\n",
    "EXPERIMENT_NAME = 'experiment_1'\n",
    "\n",
    "# 1. Load model\n",
    "print(\"[1/5] Loading model...\")\n",
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "# 2. Train\n",
    "print(\"[2/5] Starting training...\")\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=-1,\n",
    "    device=0,\n",
    "    project=f'runs/{PROJECT_NAME}',\n",
    "    name=EXPERIMENT_NAME,\n",
    "    patience=50,\n",
    "    cache=True,\n",
    "    amp=True,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "# 3. Validate\n",
    "print(\"[3/5] Validating model...\")\n",
    "metrics = model.val()\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "\n",
    "# 4. Test inference\n",
    "print(\"[4/5] Testing inference...\")\n",
    "test_results = model.predict(\n",
    "    source='path/to/test/images/',\n",
    "    save=True,\n",
    "    conf=0.25\n",
    ")\n",
    "print(f\"Processed {len(test_results)} images\")\n",
    "\n",
    "# 5. Export\n",
    "print(\"[5/5] Exporting model...\")\n",
    "model.export(format='onnx')\n",
    "print(f\"Model exported to ONNX format\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training pipeline completed successfully!\")\n",
    "print(f\"Best weights: runs/{PROJECT_NAME}/{EXPERIMENT_NAME}/weights/best.pt\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed the comprehensive course on fine-tuning Ultralytics models. You now know how to:\n",
    "\n",
    "- Train and fine-tune YOLOv5, YOLOv8, YOLOv9, YOLOv10, YOLOv11, and RT-DETR\n",
    "- Run inference and evaluate model performance\n",
    "- Modify and optimize hyperparameters for different scenarios\n",
    "- Apply advanced techniques like multi-GPU training, callbacks, and ensembles\n",
    "- Choose the right model for your specific use case\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Try different models and hyperparameters on your dataset\n",
    "2. **Read Documentation**: Visit [docs.ultralytics.com](https://docs.ultralytics.com/)\n",
    "3. **Join Community**: Participate in Ultralytics GitHub discussions\n",
    "4. **Deploy**: Export your model and deploy to production\n",
    "5. **Keep Learning**: Stay updated with new YOLO versions and features\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Ultralytics Documentation**: https://docs.ultralytics.com/\n",
    "- **GitHub Repository**: https://github.com/ultralytics/ultralytics\n",
    "- **YOLOv5 GitHub**: https://github.com/ultralytics/yolov5\n",
    "- **Roboflow Universe**: https://universe.roboflow.com/ (datasets)\n",
    "- **Papers with Code**: https://paperswithcode.com/ (research papers)\n",
    "\n",
    "Happy training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
